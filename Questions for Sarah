Questions for Sarah

5/6/16
1) Filter suggestions for public service improvements? Or should I just stick to sentiment?
	3 different natural language processing tasks
		1) Sentiment
		2) What causes sentiment 
		3) Suggestions
2) Lemmatizing, stemming, neither?
	Try both separately
3) Agglomerative Clustering, am I on the right track with the algorithm?
	Yep!
4) Other things I should try incorporating in the algorithm?
	TFDIF, 5 Nearest Neighbors, Tightness, 
5) What should my focus be right now.. hashing out the Sentiment Analysis Module? Sprucing up the application?
6) How to send jobs to EECS Servers... I'm on windows :(
	Putty
7) Independent project in the fall?
	Yes... we'll talk about that later

5/25/2016
1) Two clustering methods: Nearest Neighbor and Nearest Cluster
	Nearest Neighbor
		a. Choose a cluster
		b. Find closest neighbor with average link distance, a
		c. If neighbor in other cluster, get average link distance, b.. if not add to our cluster
		d. If neighbor in other cluster, calculate a' = a/(a + b) and b' = b/(a + b), choose two rands
		e. If a' < rand1 and b' >= rand2, change cluster id, if a' < rand1 and b' < rand2, put in contested list, else do nothing
		f. After iterating through all clusters, iterate through contested points
		g. Find X nearest neighbors not in contested list for each point
		h. Cluster id of point = mode of neighbor cluster ids, point no longer contested. If no mode, no assignment and still contested.
		i. Stop when we reach desired number of clusters
		DOES THIS MAKE SENSE??

		List of contestants vs. immediately assigning contested point to cluster with most points close to it (or doing nothing if no mode)

		Reassign all contestants at the end of each iter or do a lottery at end of each iter/cluster examination- randomly select one contestant and reassign

	Nearest Cluster 
		a. Choose a cluster
		b. Find closest cluster with average link distance, a (summing distances between members in each group, dividing by # of connections)

2) Feature frequencies vs average feature frequencies... I'm training on Yelp reviews; however, I will be testing big blocks of test containing many user comments (e.g. all comments on community development polls).. I think it makes sense to use average freqs since Yelp review is really small compared to text I will be classifying... Maybe just use feature presence 

3) EECS Servers don't have python3... Yes they do, contact root to find path

4) Perform some type of clustering.. Bundle reviews/comments belonging to same cluster, perform clustering for bundles..
Test different bundle sizes (2,3,...,n reviews), find which bundle size yields lowest spread
For first round of clustering, what should terminal # of clusters be???

5) Merging! At the end of each while loop iteration, merge the two closest in-cluster points if numClusters is the same as it was at the end of the last iteration.. 
